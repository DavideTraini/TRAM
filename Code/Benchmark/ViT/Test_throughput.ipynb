{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58ed68e-186c-4630-b336-3c1f913b1553",
   "metadata": {
    "id": "d58ed68e-186c-4630-b336-3c1f913b1553"
   },
   "source": [
    "# Librerie e Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3291b4b8-c7a5-4f58-8431-66a341882771",
   "metadata": {
    "id": "3291b4b8-c7a5-4f58-8431-66a341882771"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from torchvision.utils import make_grid\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from vit_pytorch.ats_vit import ViT as ATSViT\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "from TRAM import TRAM\n",
    "from TopK import TopK\n",
    "from PatchMergerViT import PatchMergerViT\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from thop import profile\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3",
   "metadata": {
    "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3"
   },
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7",
   "metadata": {
    "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7"
   },
   "outputs": [],
   "source": [
    "def benchmark_time(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    throw_out,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - throw_out: the percentage of runs to throw out at the start of testing\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    warm_up = int(runs * throw_out)\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                if i == warm_up:\n",
    "                    if is_cuda:\n",
    "                        torch.cuda.synchronize()\n",
    "                    total = 0\n",
    "                    start = time.time()\n",
    "\n",
    "                model(input)\n",
    "                total += batch_size\n",
    "\n",
    "    if is_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "\n",
    "    throughput = total / elapsed\n",
    "    throughput = f'{throughput:.2f}'\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Throughput: {throughput:.2f} im/s\")\n",
    "\n",
    "    return [throughput]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_flops(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    total = 0\n",
    "    total_flops = 0\n",
    "    total_params = 0\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                flops, params = profile(model, inputs=(input, ), verbose=False)\n",
    "                total += batch_size\n",
    "                total_flops += flops\n",
    "\n",
    "    flops = total_flops/total\n",
    "    flops = f'{flops/1e9:.4f}'\n",
    "    if verbose:\n",
    "        print(f\"Total FLOPs: {flops / 1e9:.4f} GFLOPs\")\n",
    "        print(f\"Total Parameters: {params / 1e6:.4f} M\")\n",
    "\n",
    "    return [flops], [params]\n",
    "\n",
    "\n",
    "\n",
    "def create_patch_list(total_patches, cut):\n",
    "    # Calcola l'importo scontato per ogni blocco di 3 elementi\n",
    "    discounted_patches = total_patches\n",
    "    patch_list = []\n",
    "    for i in range(12):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            discounted_patches = int(discounted_patches * (cut / 100))\n",
    "        patch_list.append(discounted_patches)\n",
    "    return patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e",
   "metadata": {
    "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e"
   },
   "outputs": [],
   "source": [
    "def get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df, device):\n",
    "\n",
    "    # ViT\n",
    "    print('##### ViT ####')\n",
    "    ViTnet = ViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "    )\n",
    "\n",
    "    ViTnet.to(device)\n",
    "\n",
    "    baseline_throughput = benchmark_time(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    baseline_flops, baseline_params = benchmark_flops(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n",
    "\n",
    "    # ATS\n",
    "    print('##### ATSViT ####')\n",
    "    ATSViTnet = ATSViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        max_tokens_per_depth = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    ATSViTnet.to(device)\n",
    "\n",
    "    ATS_throughput = benchmark_time(\n",
    "        ATSViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    ATS_flops, ATS_params = benchmark_flops(\n",
    "        ATSViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'ATS_{type}', 'Throughput': ATS_throughput, 'Flops': ATS_flops, 'Params': ATS_params})], ignore_index=True)\n",
    "\n",
    "    # TRAM\n",
    "    print('##### TRAM ####')\n",
    "    TRAMnet = TRAM(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        n_patch = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    TRAMnet.to(device)\n",
    "\n",
    "\n",
    "    TRAM_throughput = benchmark_time(\n",
    "        TRAMnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    TRAM_flops, TRAM_params = benchmark_flops(\n",
    "        TRAMnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'TRAM_{type}', 'Throughput': TRAM_throughput, 'Flops': TRAM_flops, 'Params': TRAM_params})], ignore_index=True)\n",
    "\n",
    "\n",
    "    print('##### Transformer_topk ####')\n",
    "    # Transformer_topk\n",
    "    Transformer_topknet = TopK(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        n_patch = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    Transformer_topknet.to(device)\n",
    "\n",
    "    Transformer_topk_throughput = benchmark_time(\n",
    "        Transformer_topknet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    Transformer_topk_flops, Transformer_topk_params = benchmark_flops(\n",
    "        Transformer_topknet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'Transformer_topk_{type}', 'Throughput': Transformer_topk_throughput, 'Flops': Transformer_topk_flops, 'Params': Transformer_topk_params})], ignore_index=True)\n",
    "\n",
    "    # Patch merger\n",
    "    print('##### PatchMerger ####')\n",
    "    PatchMergerViTnet = PatchMergerViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        patch_merge_layers = patch_merge_layers\n",
    "    )\n",
    "\n",
    "    PatchMergerViTnet.to(device)\n",
    "\n",
    "\n",
    "    PatchMerger_throughput = benchmark_time(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "\n",
    "    PatchMerger_flops, PatchMerger_params = benchmark_flops(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'PatchMerger_{type}', 'Throughput': PatchMerger_throughput, 'Flops': PatchMerger_flops, 'Params': PatchMerger_params})], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82477279-f999-4426-9a98-f5e62c9e4e41",
   "metadata": {
    "id": "82477279-f999-4426-9a98-f5e62c9e4e41"
   },
   "source": [
    "# Creazione tabella"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zF0yxkTalOAc",
   "metadata": {
    "id": "zF0yxkTalOAc"
   },
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "h3h1nW2llOAo",
   "metadata": {
    "id": "h3h1nW2llOAo"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "patch_size = 16\n",
    "runs_time = 10\n",
    "runs_flops = 10\n",
    "input_size = (3, 160, 160)\n",
    "img_size = 160\n",
    "\n",
    "att_dim = 768\n",
    "depth = 12\n",
    "heads = 12\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "total_patches = int((img_size/patch_size)**2)\n",
    "cut = 50\n",
    "max_tokens_per_depth = create_patch_list(total_patches, cut)\n",
    "\n",
    "patch_merge_layers = [(2, max_tokens_per_depth[3]),(5, max_tokens_per_depth[6]),(8, max_tokens_per_depth[9])] \n",
    "\n",
    "type = 'Base'\n",
    "\n",
    "df_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01UR_jedlOAo",
   "metadata": {
    "id": "01UR_jedlOAo",
    "outputId": "9a8df396-f3be-4b67-c122-83e3fb7ebf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/3413190668.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ATSViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### TRAM ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ZmL9RyNlOAp",
   "metadata": {
    "id": "5ZmL9RyNlOAp"
   },
   "outputs": [],
   "source": [
    "att_dim = 384\n",
    "depth = 12\n",
    "heads = 6\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Small'\n",
    "\n",
    "df_small_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bwRvlOwrlOAp",
   "metadata": {
    "id": "bwRvlOwrlOAp",
    "outputId": "9cf70fa4-892e-434b-b934-736747f150f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### ATSViT ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/3413190668.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "##### TRAM ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_small_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_small_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oQ1D4iiclOAp",
   "metadata": {
    "id": "oQ1D4iiclOAp"
   },
   "outputs": [],
   "source": [
    "att_dim = 192\n",
    "depth = 12\n",
    "heads = 3\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Tiny'\n",
    "\n",
    "df_tiny_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4RaWtHY0lOAp",
   "metadata": {
    "id": "4RaWtHY0lOAp",
    "outputId": "8e41d0a8-f917-4765-f511-d5759279c954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/3413190668.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ATSViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### TRAM ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_tiny_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_tiny_gpu, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b15d4-9a35-4938-bd53-d76df4c6956e",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Z9IdAsRgll7d",
   "metadata": {
    "id": "Z9IdAsRgll7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Base</td>\n",
       "      <td>797.42</td>\n",
       "      <td>8.6502</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Base</td>\n",
       "      <td>1028.02</td>\n",
       "      <td>4.0989</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAM_Base</td>\n",
       "      <td>1417.91</td>\n",
       "      <td>4.3279</td>\n",
       "      <td>85626634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Base</td>\n",
       "      <td>1464.82</td>\n",
       "      <td>4.3285</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Base</td>\n",
       "      <td>1645.99</td>\n",
       "      <td>4.0357</td>\n",
       "      <td>85634314.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modello Throughput   Flops      Params\n",
       "0           ViT_net_Base     797.42  8.6502  85629706.0\n",
       "1               ATS_Base    1028.02  4.0989  85629706.0\n",
       "2              TRAM_Base    1417.91  4.3279  85626634.0\n",
       "3  Transformer_topk_Base    1464.82  4.3285  85629706.0\n",
       "4       PatchMerger_Base    1645.99  4.0357  85634314.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Small</td>\n",
       "      <td>2019.67</td>\n",
       "      <td>2.1806</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Small</td>\n",
       "      <td>1559.74</td>\n",
       "      <td>1.0397</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAM_Small</td>\n",
       "      <td>3339.73</td>\n",
       "      <td>1.0981</td>\n",
       "      <td>21579658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Small</td>\n",
       "      <td>3529.12</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Small</td>\n",
       "      <td>4059.30</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>21584266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modello Throughput   Flops      Params\n",
       "0           ViT_net_Small    2019.67  2.1806  21581962.0\n",
       "1               ATS_Small    1559.74  1.0397  21581962.0\n",
       "2              TRAM_Small    3339.73  1.0981  21579658.0\n",
       "3  Transformer_topk_Small    3529.12  1.0986  21581962.0\n",
       "4       PatchMerger_Small    4059.30  1.0254  21584266.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Tiny</td>\n",
       "      <td>4080.73</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Tiny</td>\n",
       "      <td>1804.20</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAM_Tiny</td>\n",
       "      <td>6318.01</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>5481418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Tiny</td>\n",
       "      <td>6748.70</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Tiny</td>\n",
       "      <td>8196.53</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>5484490.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modello Throughput   Flops     Params\n",
       "0           ViT_net_Tiny    4080.73  0.5543  5483338.0\n",
       "1               ATS_Tiny    1804.20  0.2678  5483338.0\n",
       "2              TRAM_Tiny    6318.01  0.2826  5481418.0\n",
       "3  Transformer_topk_Tiny    6748.70  0.2830  5483338.0\n",
       "4       PatchMerger_Tiny    8196.53  0.2647  5484490.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_gpu), display(df_small_gpu), display(df_tiny_gpu)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d58ed68e-186c-4630-b336-3c1f913b1553"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
