{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58ed68e-186c-4630-b336-3c1f913b1553",
   "metadata": {
    "id": "d58ed68e-186c-4630-b336-3c1f913b1553",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Librerie e Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3291b4b8-c7a5-4f58-8431-66a341882771",
   "metadata": {
    "id": "3291b4b8-c7a5-4f58-8431-66a341882771"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from torchvision.utils import make_grid\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from vit_pytorch.ats_vit import ViT as ATSViT\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "from MultiViT import MultiViT\n",
    "from TopK import ViT_topk\n",
    "from PatchMergerViT import PatchMergerViT\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from thop import profile\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3",
   "metadata": {
    "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3"
   },
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7",
   "metadata": {
    "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7"
   },
   "outputs": [],
   "source": [
    "def benchmark_time(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    throw_out,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - throw_out: the percentage of runs to throw out at the start of testing\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    warm_up = int(runs * throw_out)\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                if i == warm_up:\n",
    "                    if is_cuda:\n",
    "                        torch.cuda.synchronize()\n",
    "                    total = 0\n",
    "                    start = time.time()\n",
    "\n",
    "                model(input)\n",
    "                total += batch_size\n",
    "\n",
    "    if is_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "\n",
    "    throughput = total / elapsed\n",
    "    throughput = f'{throughput:.2f}'\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Throughput: {throughput:.2f} im/s\")\n",
    "\n",
    "    return [throughput]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_flops(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    total = 0\n",
    "    total_flops = 0\n",
    "    total_params = 0\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                flops, params = profile(model, inputs=(input, ), verbose=False)\n",
    "                total += batch_size\n",
    "                total_flops += flops\n",
    "\n",
    "    flops = total_flops/total\n",
    "    flops = f'{flops/1e9:.4f}'\n",
    "    if verbose:\n",
    "        print(f\"Total FLOPs: {flops / 1e9:.4f} GFLOPs\")\n",
    "        print(f\"Total Parameters: {params / 1e6:.4f} M\")\n",
    "\n",
    "    return [flops], [params]\n",
    "\n",
    "\n",
    "\n",
    "def create_patch_list(total_patches, cut):\n",
    "    # Calcola l'importo scontato per ogni blocco di 3 elementi\n",
    "    discounted_patches = total_patches\n",
    "    patch_list = []\n",
    "    for i in range(12):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            discounted_patches = int(discounted_patches * (cut / 100))\n",
    "        patch_list.append(discounted_patches)\n",
    "    return patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e",
   "metadata": {
    "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e"
   },
   "outputs": [],
   "source": [
    "def get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df, device):\n",
    "\n",
    "    # ViT\n",
    "    print('##### ViT ####')\n",
    "    ViTnet = ViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "    )\n",
    "\n",
    "    ViTnet.to(device)\n",
    "\n",
    "    baseline_throughput = benchmark_time(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    baseline_flops, baseline_params = benchmark_flops(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n",
    "\n",
    "    # ATS\n",
    "    print('##### ATSViT ####')\n",
    "    ATSViTnet = ATSViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        max_tokens_per_depth = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    ATSViTnet.to(device)\n",
    "\n",
    "    ATS_throughput = benchmark_time(\n",
    "        ATSViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    ATS_flops, ATS_params = benchmark_flops(\n",
    "        ATSViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'ATS_{type}', 'Throughput': ATS_throughput, 'Flops': ATS_flops, 'Params': ATS_params})], ignore_index=True)\n",
    "\n",
    "    # MultiViT\n",
    "    print('##### MultiViT ####')\n",
    "    MultiViTnet = MultiViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        n_patch = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    MultiViTnet.to(device)\n",
    "\n",
    "\n",
    "    MultiViT_throughput = benchmark_time(\n",
    "        MultiViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    MultiViT_flops, MultiViT_params = benchmark_flops(\n",
    "        MultiViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'MultiViT_{type}', 'Throughput': MultiViT_throughput, 'Flops': MultiViT_flops, 'Params': MultiViT_params})], ignore_index=True)\n",
    "\n",
    "\n",
    "    print('##### Transformer_topk ####')\n",
    "    # Transformer_topk\n",
    "    Transformer_topknet = ViT_topk(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        n_patch = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    Transformer_topknet.to(device)\n",
    "\n",
    "    Transformer_topk_throughput = benchmark_time(\n",
    "        Transformer_topknet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    Transformer_topk_flops, Transformer_topk_params = benchmark_flops(\n",
    "        Transformer_topknet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'Transformer_topk_{type}', 'Throughput': Transformer_topk_throughput, 'Flops': Transformer_topk_flops, 'Params': Transformer_topk_params})], ignore_index=True)\n",
    "\n",
    "    # Patch merger\n",
    "    print('##### PatchMerger ####')\n",
    "    PatchMergerViTnet = PatchMergerViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        patch_merge_layers = patch_merge_layers\n",
    "    )\n",
    "\n",
    "    PatchMergerViTnet.to(device)\n",
    "\n",
    "\n",
    "    PatchMerger_throughput = benchmark_time(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "\n",
    "    PatchMerger_flops, PatchMerger_params = benchmark_flops(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'PatchMerger_{type}', 'Throughput': PatchMerger_throughput, 'Flops': PatchMerger_flops, 'Params': PatchMerger_params})], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82477279-f999-4426-9a98-f5e62c9e4e41",
   "metadata": {
    "id": "82477279-f999-4426-9a98-f5e62c9e4e41"
   },
   "source": [
    "# Creazione tabella"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zF0yxkTalOAc",
   "metadata": {
    "id": "zF0yxkTalOAc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "h3h1nW2llOAo",
   "metadata": {
    "id": "h3h1nW2llOAo"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "patch_size = 16\n",
    "runs_time = 10\n",
    "runs_flops = 10\n",
    "input_size = (3, 160, 160)\n",
    "img_size = 160\n",
    "\n",
    "att_dim = 768\n",
    "depth = 12\n",
    "heads = 12\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "total_patches = int((img_size/patch_size)**2)\n",
    "cut = 50\n",
    "max_tokens_per_depth = create_patch_list(total_patches, cut)\n",
    "\n",
    "patch_merge_layers = [(2, max_tokens_per_depth[3]),(5, max_tokens_per_depth[6]),(8, max_tokens_per_depth[9])] \n",
    "\n",
    "type = 'Base'\n",
    "\n",
    "df_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01UR_jedlOAo",
   "metadata": {
    "id": "01UR_jedlOAo",
    "outputId": "9a8df396-f3be-4b67-c122-83e3fb7ebf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2676/1566234595.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ATSViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### MultiViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ZmL9RyNlOAp",
   "metadata": {
    "id": "5ZmL9RyNlOAp"
   },
   "outputs": [],
   "source": [
    "att_dim = 384\n",
    "depth = 12\n",
    "heads = 6\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Small'\n",
    "\n",
    "df_small_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bwRvlOwrlOAp",
   "metadata": {
    "id": "bwRvlOwrlOAp",
    "outputId": "9cf70fa4-892e-434b-b934-736747f150f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### ATSViT ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2676/1566234595.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "##### MultiViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_small_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_small_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "oQ1D4iiclOAp",
   "metadata": {
    "id": "oQ1D4iiclOAp"
   },
   "outputs": [],
   "source": [
    "att_dim = 192\n",
    "depth = 12\n",
    "heads = 3\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Tiny'\n",
    "\n",
    "df_tiny_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4RaWtHY0lOAp",
   "metadata": {
    "id": "4RaWtHY0lOAp",
    "outputId": "8e41d0a8-f917-4765-f511-d5759279c954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ViT ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2676/1566234595.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ATSViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### MultiViT ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### Transformer_topk ####\n",
      "cuda:0\n",
      "cuda:0\n",
      "##### PatchMerger ####\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df_tiny_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_tiny_gpu, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b15d4-9a35-4938-bd53-d76df4c6956e",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "Z9IdAsRgll7d",
   "metadata": {
    "id": "Z9IdAsRgll7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Base</td>\n",
       "      <td>800.46</td>\n",
       "      <td>8.6502</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Base</td>\n",
       "      <td>1037.71</td>\n",
       "      <td>4.0943</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiViT_Base</td>\n",
       "      <td>1408.75</td>\n",
       "      <td>4.3279</td>\n",
       "      <td>85626634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Base</td>\n",
       "      <td>1459.81</td>\n",
       "      <td>4.3285</td>\n",
       "      <td>85629706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Base</td>\n",
       "      <td>1636.96</td>\n",
       "      <td>4.0357</td>\n",
       "      <td>85634314.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modello Throughput   Flops      Params\n",
       "0           ViT_net_Base     800.46  8.6502  85629706.0\n",
       "1               ATS_Base    1037.71  4.0943  85629706.0\n",
       "2          MultiViT_Base    1408.75  4.3279  85626634.0\n",
       "3  Transformer_topk_Base    1459.81  4.3285  85629706.0\n",
       "4       PatchMerger_Base    1636.96  4.0357  85634314.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Small</td>\n",
       "      <td>2031.59</td>\n",
       "      <td>2.1806</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Small</td>\n",
       "      <td>1618.46</td>\n",
       "      <td>1.0380</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiViT_Small</td>\n",
       "      <td>3319.77</td>\n",
       "      <td>1.0981</td>\n",
       "      <td>21579658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Small</td>\n",
       "      <td>3502.97</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>21581962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Small</td>\n",
       "      <td>3868.73</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>21584266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modello Throughput   Flops      Params\n",
       "0           ViT_net_Small    2031.59  2.1806  21581962.0\n",
       "1               ATS_Small    1618.46  1.0380  21581962.0\n",
       "2          MultiViT_Small    3319.77  1.0981  21579658.0\n",
       "3  Transformer_topk_Small    3502.97  1.0986  21581962.0\n",
       "4       PatchMerger_Small    3868.73  1.0254  21584266.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Flops</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT_net_Tiny</td>\n",
       "      <td>4026.10</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_Tiny</td>\n",
       "      <td>1855.31</td>\n",
       "      <td>0.2682</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiViT_Tiny</td>\n",
       "      <td>6478.06</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>5481418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer_topk_Tiny</td>\n",
       "      <td>6711.60</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>5483338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchMerger_Tiny</td>\n",
       "      <td>7911.24</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>5484490.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modello Throughput   Flops     Params\n",
       "0           ViT_net_Tiny    4026.10  0.5543  5483338.0\n",
       "1               ATS_Tiny    1855.31  0.2682  5483338.0\n",
       "2          MultiViT_Tiny    6478.06  0.2826  5481418.0\n",
       "3  Transformer_topk_Tiny    6711.60  0.2830  5483338.0\n",
       "4       PatchMerger_Tiny    7911.24  0.2647  5484490.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_gpu), display(df_small_gpu), display(df_tiny_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e57ab-c334-4e39-88de-21ae32f88f1c",
   "metadata": {
    "id": "c05e57ab-c334-4e39-88de-21ae32f88f1c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prove a caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "110ebb43-ba2f-458a-93d5-6a66ce668de2",
   "metadata": {
    "id": "110ebb43-ba2f-458a-93d5-6a66ce668de2"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def quad(lista):\n",
    "    somma = 0\n",
    "    for elem in lista:\n",
    "        somma += elem**2\n",
    "    return somma    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68aa248b-26b7-4014-8829-c10560e59d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([100, 90, 80, 70, 65, 60, 55, 50, 45, 40, 35, 30])/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5b5708-08e3-4cfb-b36c-2883ec718d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad([100, 90, 80, 70, 65, 60, 55, 50, 45, 40, 35, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6852eeb7-73e6-4d6b-805a-757553748ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([100, 100, 100, 100, 100, 100, 20, 20, 20, 20, 20, 20])/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95c50eb-5555-4745-bee3-5ce50a073827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad([100, 100, 100, 100, 100, 100, 20, 20, 20, 20, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1434fcb2-5d82-4422-ab5f-4b60cbd20ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10, 5])/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ef38170-831b-41bf-b811-eecb4fe35d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad([60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa8c126-0510-4366-8b79-bf3d0c76133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([100, 100, 100, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c30de4-9d4f-4d40-998f-d91c171648b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30576"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad([100, 100, 100, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180053ef-2b59-422f-808b-4dee3c1cef62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d58ed68e-186c-4630-b336-3c1f913b1553"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
