{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58ed68e-186c-4630-b336-3c1f913b1553",
   "metadata": {
    "id": "d58ed68e-186c-4630-b336-3c1f913b1553"
   },
   "source": [
    "# Librerie e Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291b4b8-c7a5-4f58-8431-66a341882771",
   "metadata": {
    "id": "3291b4b8-c7a5-4f58-8431-66a341882771"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from torchvision.utils import make_grid\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from vit_pytorch import SimpleViT as ViT\n",
    "\n",
    "from TRAM import TRAM\n",
    "from PatchMergerViT import PatchMergerViT\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from thop import profile\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3",
   "metadata": {
    "id": "75a86dcf-4ef7-426f-bde1-f7636152ebb3"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7",
   "metadata": {
    "id": "baf78064-db6d-4a48-b5ae-867ce9ab21f7"
   },
   "outputs": [],
   "source": [
    "def benchmark_time(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    throw_out,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - throw_out: the percentage of runs to throw out at the start of testing\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    warm_up = int(runs * throw_out)\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                if i == warm_up:\n",
    "                    if is_cuda:\n",
    "                        torch.cuda.synchronize()\n",
    "                    total = 0\n",
    "                    start = time.time()\n",
    "\n",
    "                model(input)\n",
    "                total += batch_size\n",
    "\n",
    "    if is_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "\n",
    "    throughput = total / elapsed\n",
    "    throughput = f'{throughput:.2f}'\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Throughput: {throughput:.2f} im/s\")\n",
    "\n",
    "    return [throughput]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_flops(\n",
    "    model,\n",
    "    device,\n",
    "    input_size,\n",
    "    batch_size,\n",
    "    runs,\n",
    "    verbose,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark the given model with random inputs at the given batch size.\n",
    "\n",
    "    Args:\n",
    "     - model: the module to benchmark\n",
    "     - device: the device to use for benchmarking\n",
    "     - input_size: the input size to pass to the model (channels, h, w)\n",
    "     - batch_size: the batch size to use for evaluation\n",
    "     - runs: the number of total runs to do\n",
    "     - verbose: whether or not to use tqdm to print progress / print throughput at end\n",
    "\n",
    "    Returns:\n",
    "     - the throughput measured in images / second\n",
    "    \"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    is_cuda = torch.device(device).type == \"cuda\"\n",
    "\n",
    "    model = model.eval().to(device)\n",
    "    print(device)\n",
    "    input = torch.rand(batch_size, *input_size, device=device)\n",
    "\n",
    "    total = 0\n",
    "    total_flops = 0\n",
    "    total_params = 0\n",
    "\n",
    "    with torch.autocast(device.type):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(runs), disable=not verbose, desc=\"Benchmarking\"):\n",
    "                flops, params = profile(model, inputs=(input, ), verbose=False)\n",
    "                total += batch_size\n",
    "                total_flops += flops\n",
    "\n",
    "    flops = total_flops/total\n",
    "    flops = f'{flops/1e9:.4f}'\n",
    "    if verbose:\n",
    "        print(f\"Total FLOPs: {flops / 1e9:.4f} GFLOPs\")\n",
    "        print(f\"Total Parameters: {params / 1e6:.4f} M\")\n",
    "\n",
    "    return [flops], [params]\n",
    "\n",
    "\n",
    "\n",
    "def create_patch_list(total_patches, cut):\n",
    "    # Calcola l'importo scontato per ogni blocco di 3 elementi\n",
    "    discounted_patches = total_patches\n",
    "    patch_list = []\n",
    "    for i in range(12):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            discounted_patches = int(discounted_patches * (cut / 100))\n",
    "        patch_list.append(discounted_patches)\n",
    "    return patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e",
   "metadata": {
    "id": "c55da31a-fa55-464e-8c80-cdc0f33d357e"
   },
   "outputs": [],
   "source": [
    "def get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df, device):\n",
    "\n",
    "    # ViT\n",
    "    print('##### ViT ####')\n",
    "    ViTnet = ViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "    )\n",
    "\n",
    "    ViTnet.to(device)\n",
    "\n",
    "    baseline_throughput = benchmark_time(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    baseline_flops, baseline_params = benchmark_flops(\n",
    "        ViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'ViT_net_{type}', 'Throughput': baseline_throughput, 'Flops': baseline_flops, 'Params': baseline_params})], ignore_index=True)\n",
    "\n",
    "    \n",
    "    # TRAM\n",
    "    print('##### TRAM ####')\n",
    "    TRAMnet = TRAM(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        n_patch = max_tokens_per_depth\n",
    "    )\n",
    "\n",
    "    TRAMnet.to(device)\n",
    "\n",
    "\n",
    "    TRAM_throughput = benchmark_time(\n",
    "        TRAMnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "    TRAM_flops, TRAM_params = benchmark_flops(\n",
    "        TRAMnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'TRAM_{type}', 'Throughput': TRAM_throughput, 'Flops': TRAM_flops, 'Params': TRAM_params})], ignore_index=True)\n",
    "\n",
    "\n",
    "    # Patch merger\n",
    "    print('##### PatchMerger ####')\n",
    "    PatchMergerViTnet = PatchMergerViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = att_dim,\n",
    "        depth = depth,\n",
    "        heads = heads,\n",
    "        mlp_dim = mlp_dim,\n",
    "        patch_merge_layers = patch_merge_layers\n",
    "    )\n",
    "\n",
    "    PatchMergerViTnet.to(device)\n",
    "\n",
    "\n",
    "    PatchMerger_throughput = benchmark_time(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size,\n",
    "        throw_out = 0.25\n",
    "    )\n",
    "\n",
    "\n",
    "    PatchMerger_flops, PatchMerger_params = benchmark_flops(\n",
    "        PatchMergerViTnet,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        runs=runs_time,\n",
    "        batch_size=batch_size,\n",
    "        input_size=input_size\n",
    "    )\n",
    "\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'Modello': f'PatchMerger_{type}', 'Throughput': PatchMerger_throughput, 'Flops': PatchMerger_flops, 'Params': PatchMerger_params})], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82477279-f999-4426-9a98-f5e62c9e4e41",
   "metadata": {
    "id": "82477279-f999-4426-9a98-f5e62c9e4e41"
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1be0b8-8939-4ad5-9947-99d5f540766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 16\n",
    "runs_time = 10\n",
    "runs_flops = 10\n",
    "input_size = (3, 160, 160)\n",
    "img_size = 160\n",
    "total_patches = int((img_size/patch_size)**2)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "cut = 50\n",
    "max_tokens_per_depth = create_patch_list(total_patches, cut)\n",
    "patch_merge_layers = [(2, max_tokens_per_depth[3]),(5, max_tokens_per_depth[6]),(8, max_tokens_per_depth[9])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h3h1nW2llOAo",
   "metadata": {
    "id": "h3h1nW2llOAo"
   },
   "outputs": [],
   "source": [
    "att_dim = 768\n",
    "depth = 12\n",
    "heads = 12\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Base'\n",
    "\n",
    "df_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01UR_jedlOAo",
   "metadata": {
    "id": "01UR_jedlOAo",
    "outputId": "9a8df396-f3be-4b67-c122-83e3fb7ebf98"
   },
   "outputs": [],
   "source": [
    "df_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ZmL9RyNlOAp",
   "metadata": {
    "id": "5ZmL9RyNlOAp"
   },
   "outputs": [],
   "source": [
    "att_dim = 384\n",
    "depth = 12\n",
    "heads = 6\n",
    "mlp_dim = att_dim * 4\n",
    "\n",
    "type = 'Small'\n",
    "\n",
    "df_small_gpu = pd.DataFrame(columns = ['Modello', 'Throughput', 'Flops', 'Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bwRvlOwrlOAp",
   "metadata": {
    "id": "bwRvlOwrlOAp",
    "outputId": "9cf70fa4-892e-434b-b934-736747f150f3"
   },
   "outputs": [],
   "source": [
    "df_small_gpu = get_results(batch_size, patch_size, runs_time, runs_flops, input_size, img_size, att_dim, depth, heads, mlp_dim, max_tokens_per_depth, patch_merge_layers, type, df_small_gpu, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b15d4-9a35-4938-bd53-d76df4c6956e",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z9IdAsRgll7d",
   "metadata": {
    "id": "Z9IdAsRgll7d"
   },
   "outputs": [],
   "source": [
    "display(df_gpu), display(df_small_gpu)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d58ed68e-186c-4630-b336-3c1f913b1553"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
