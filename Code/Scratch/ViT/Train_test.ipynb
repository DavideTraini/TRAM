{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXC93PvZHALw"
   },
   "source": [
    "# Import e path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBKm4O3pn19s"
   },
   "outputs": [],
   "source": [
    "results_save_path = \"../../Results/\"\n",
    "dataset_path = \"../../Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as functional\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from vit_pytorch.ats_vit import ViT as ATS\n",
    "from vit_pytorch import ViT\n",
    "from PatchMerger import PatchMerger\n",
    "from TRAM import TRAM\n",
    "from TopK import TopK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi1SBM-8TRqg"
   },
   "source": [
    "## Validi per ogni modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIBVHD-TTU6u"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qL0i8NnGpUPc"
   },
   "outputs": [],
   "source": [
    "# Verifica se la GPU Ã¨ disponibile\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni per train e validation del modello RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter(model, optimz, data_load, loss_val, device, scheduler):\n",
    "    samples = len(data_load.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_load):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimz.zero_grad()\n",
    "        out = functional.log_softmax(model(data), dim=1)\n",
    "        loss = functional.nll_loss(out, target)\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "    scheduler.step()\n",
    "    print(scheduler.get_last_lr())\n",
    "    loss_val.append(loss.item())\n",
    "\n",
    "def evaluate(model, optimizer, data_load, loss_val, device):\n",
    "    model.eval()\n",
    "\n",
    "    samples = len(data_load.dataset)\n",
    "    # predizioni corrette\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = functional.log_softmax(model(data), dim=1)\n",
    "            loss = functional.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target).sum()\n",
    "\n",
    "    aloss = tloss / samples\n",
    "    loss_val.append(aloss)\n",
    "    acc = (100.0 * csamp / samples).cpu()\n",
    "\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(acc) + '%)\\n')\n",
    "\n",
    "    return acc\n",
    "\n",
    "def train_validation(model, optimizer, train_loader, validation_loader, dataset_name, epoche,scheduler, device):\n",
    "  tr_loss, ts_loss, ts_acc, epoch_time_list = [], [], [], []\n",
    "\n",
    "  for epoch in range(1, epoche + 1):\n",
    "\n",
    "      start_time = time.time()\n",
    "\n",
    "      print(f'Epoch: {epoch}/{epoche}')\n",
    "      print(\"INIZIO TRAINING\")\n",
    "      train_iter(model, optimizer, train_loader, tr_loss, device, scheduler= scheduler)\n",
    "      print(\"INIZIO VALIDATION\")\n",
    "      acc = evaluate(model, optimizer, validation_loader, ts_loss, device)\n",
    "\n",
    "      ts_acc.append(acc)\n",
    "\n",
    "\n",
    "      epoch_time = time.time() - start_time\n",
    "      epoch_time_list.append(epoch_time)\n",
    "\n",
    "      print('Execution time:', '{:5.2f}'.format(epoch_time), 'seconds')\n",
    "      print(\"#\"*40)\n",
    "\n",
    "  return tr_loss, ts_loss, ts_acc, epoch_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG2VBWH-HmoI"
   },
   "source": [
    "## Funzioni per train e validation del modello SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NslZrU5FGFWo"
   },
   "outputs": [],
   "source": [
    "def train_iter_sampling(model, optimz, data_load, loss_val, device, n_patch,scheduler):\n",
    "    samples = len(data_load.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_load):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimz.zero_grad()\n",
    "        out = functional.log_softmax(model(data, n_patch), dim=1)\n",
    "        loss = functional.nll_loss(out, target)\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "    scheduler.step()\n",
    "    print(scheduler.get_last_lr())\n",
    "    loss_val.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiazmHl-QtQ_"
   },
   "outputs": [],
   "source": [
    "def evaluate_sampling(model, optimizer, data_load, loss_val, device, n_patch):\n",
    "    model.eval()\n",
    "\n",
    "    samples = len(data_load.dataset)\n",
    "    # predizioni corrette\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = functional.log_softmax(model(data, n_patch), dim=1)\n",
    "            loss = functional.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target).sum()\n",
    "\n",
    "    aloss = tloss / samples\n",
    "    loss_val.append(aloss)\n",
    "    acc = (100.0 * csamp / samples).cpu()\n",
    "\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(acc) + '%)\\n')\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9XmFO4NXfvR"
   },
   "outputs": [],
   "source": [
    "def train_validation_sampling(model, optimizer, train_loader, validation_loader, dataset_name, epoche, device, n_patch, scheduler):\n",
    "  tr_loss, ts_loss, ts_acc, epoch_time_list = [], [], [], []\n",
    "\n",
    "  for epoch in range(1, epoche + 1):\n",
    "\n",
    "      start_time = time.time()\n",
    "\n",
    "      print(f'Epoch: {epoch}/{epoche}')\n",
    "      print(\"INIZIO TRAINING\")\n",
    "      train_iter_sampling(model, optimizer, train_loader, tr_loss, device, n_patch, scheduler)\n",
    "      print(\"INIZIO VALIDATION\")\n",
    "      acc = evaluate_sampling(model, optimizer, validation_loader, ts_loss, device, n_patch)\n",
    "\n",
    "      ts_acc.append(acc)\n",
    "\n",
    "\n",
    "      epoch_time = time.time() - start_time\n",
    "      epoch_time_list.append(epoch_time)\n",
    "\n",
    "      print('Execution time:', '{:5.2f}'.format(epoch_time), 'seconds')\n",
    "      print(\"#\"*40)\n",
    "\n",
    "  return tr_loss, ts_loss, ts_acc, epoch_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViT_train_test_save(dataset_name, model, n_patch = None):\n",
    "    \n",
    "    model.to(device)\n",
    "    # definiamo l'ottimizzatore\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer,step_size=10, gamma=0.5)\n",
    "    initial = time.time()\n",
    "    if n_patch == None: \n",
    "        _, _, validation_acc, epoch_time = train_validation(model, optimizer, train_loader, val_loader, dataset_name, epoche, device = device, scheduler = scheduler)\n",
    "    else:\n",
    "        _, _, validation_acc, epoch_time = train_validation_sampling(model, optimizer, train_loader, val_loader, dataset_name, epoche, device = device, n_patch = n_patch, scheduler = scheduler)\n",
    "    print(f'Total Time: {time.time()-initial}')\n",
    "    \n",
    "    df = pd.DataFrame({'validation_acc': [tensor.item() for tensor in validation_acc],\n",
    "                       'epoch_time': epoch_time\n",
    "                       })\n",
    "    \n",
    "    if not os.path.exists(results_save_path):\n",
    "        os.makedirs(results_save_path)\n",
    "        \n",
    "    df.to_csv(f'{results_save_path}{dataset_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_size = 160\n",
    "patch_size = 16\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "trans = transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x)\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomRotation(10),  # Random rotation by 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color Jitter\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Vertical flip with 50% probability\n",
    "    transforms.RandomResizedCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    trans,\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    trans,\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "trainset = torchvision.datasets.Imagenette(root=dataset_path, split='train', transform=transform_train) #download=True,\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "validationset = torchvision.datasets.Imagenette(root=dataset_path, split='val', transform=transform_validation) #download=True\n",
    "val_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_base = 768\n",
    "dim_small = 384\n",
    "\n",
    "heads_base = 12\n",
    "heads_small = 6\n",
    "\n",
    "n_patch_75 = [100, 100, 100, 75, 75, 75, 56, 56, 56, 42, 42, 42]\n",
    "n_patch_50 = [100, 100, 100, 50, 50, 50, 25, 25, 25, 12, 12, 12]\n",
    "\n",
    "n_patch_75_PM = [(2,75),(5,56),(8,42)]\n",
    "n_patch_50_PM = [(2,50),(5,25),(8,12)]\n",
    "\n",
    "epoche = 1\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViTnet_base = ViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small = ViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_75%\", model = ViTnet_base)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_50%\", model = ViTnet_base)\n",
    "\n",
    "\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_75%\", model = ViTnet_small)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_50%\", model = ViTnet_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViTnet_base = TRAM(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small = TRAM(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_TRAM_75%\", model = ViTnet_base, n_patch = n_patch_75)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_TRAM_50%\", model = ViTnet_base, n_patch = n_patch_50)\n",
    "\n",
    "\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_TRAM_75%\", model = ViTnet_small, n_patch = n_patch_75)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_TRAM_50%\", model = ViTnet_small, n_patch = n_patch_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PatchMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViTnet_base_75 = PatchMerger(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        patch_merge_layers = n_patch_75_PM\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small_75 = PatchMerger(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        patch_merge_layers = n_patch_75_PM\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ViTnet_base_50 = PatchMerger(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        patch_merge_layers = n_patch_50_PM\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small_50 = PatchMerger(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        patch_merge_layers = n_patch_50_PM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_PatchMerger_75%\", model = ViTnet_base_75)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_PatchMerger_50%\", model = ViTnet_base_50)\n",
    "\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_PatchMerger_75%\", model = ViTnet_small_75)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_PatchMerger_50%\", model = ViTnet_small_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViTnet_base = TopK(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small = TopK(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_TopK_75%\", model = ViTnet_base, n_patch = n_patch_75_PM)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_TopK_50%\", model = ViTnet_base, n_patch = n_patch_50_PM)\n",
    "\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_TopK_75%\", ViTnet_small, n_patch = n_patch_75_PM)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_TopK_50%\", ViTnet_small, n_patch = n_patch_50_PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViTnet_base = ATS(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_base,\n",
    "        depth = 12,\n",
    "        heads = heads_base,\n",
    "        mlp_dim = dim_base*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "ViTnet_small = ATS(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = 10,\n",
    "        dim = dim_small,\n",
    "        depth = 12,\n",
    "        heads = heads_small,\n",
    "        mlp_dim = dim_small*4,\n",
    "        dropout = 0,\n",
    "        emb_dropout = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_ATS_75%\", model = ViTnet_base, n_patch = n_patch_75_PM)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTBase_ATS_50%\", model = ViTnet_base, n_patch = n_patch_50_PM)\n",
    "\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_ATS_75%\", ViTnet_small, n_patch = n_patch_75_PM)\n",
    "ViT_train_test_save(dataset_name = \"imaginette_ViTSmall_ATS_50%\", ViTnet_small, n_patch = n_patch_50_PM)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rXC93PvZHALw",
    "-WOxO6GNga2i",
    "xTio5oHEG9sv",
    "ng75uqlIgCvl",
    "SWAh2lXxHQhL",
    "QTJ-jgfrQ68o"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
