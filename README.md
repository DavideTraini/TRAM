# ViT-Visual-Interpretability

This is the official implementation of the paper: TRAM.

## Abstract

![Multilayer creation](Readme_imgs/Workflow.png)



![Selected tokens 50 tench](Readme_imgs/0_50_tench-1.png)
![Selected tokens 75 tench](Readme_imgs/0_75_tench-1.png)


![Selected tokens 50 church](Readme_imgs/33_50_church-1.png)
![Selected tokens 75 church](Readme_imgs/33_75_church-1.png)


![Selected tokens 50 parachute](Readme_imgs/17_50_parachute-1.png)
![Selected tokens 75 parachute](Readme_imgs/17_75_parachute-1.png)


## Usage

This repository can be directly downloaded and executed locally. The required libraries are displayed in Section [Requirements](#requirements)


## Parameters 
In the **Usage_sample** file the user can modify the following parameters:

### Initialization parameters

### Call Parameters




## Requirements <a name="requirements"></a>

In our notebook we used the following libraries:
```
PIL=9.2.0  
scipy=1.9.3  
transformers=4.30.2  
torch=2.1.2+cu121  
torchvision=0.16.2+cu121  
sklearn=1.4.1.post1  
numpy=1.24.4  
pandas=2.1.4  
matplotlib=3.8.2
seaborn=0.13.1  
```


## Citation

If you use this model for your research please cite our paper.